{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55198f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#Reed API key\n",
    "api_key = \"532d0640-6b26-4083-974c-1bbd034ae1df\"\n",
    "\n",
    "# Encode API key using Base64\n",
    "encoded_api_key = base64.b64encode(f\"{api_key}:\".encode()).decode()\n",
    "\n",
    "# Define API endpoint\n",
    "url = \"https://www.reed.co.uk/api/1.0/search\"\n",
    "\n",
    "# Keywords to search\n",
    "search_keywords = [\n",
    "    \"Data Analyst\", \"Data Scientist\", \"Business Intelligence Analyst\", \"BI Analyst\", \"Machine Learning Engineer\",\n",
    "    \"AI Engineer\", \"Data Engineer\", \"Analytics Consultant\", \"Big Data Analyst\", \"SQL Analyst\", \"Power BI Developer\"\n",
    "]\n",
    "\n",
    "# Set headers with authentication\n",
    "headers = {\"Authorization\": f\"Basic {encoded_api_key}\"}\n",
    "\n",
    "# File path for saving job data in CSV format\n",
    "csv_path = \"/Users/kirancorreya/Downloads/reed_jobs_full_description.csv\"\n",
    "\n",
    "# Open CSV for writing\n",
    "with open(csv_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Job Title\", \"Company\", \"Location\", \"Minimum Salary\", \"Maximum Salary\", \"Contract Type\", \"Job Type\", \"Date Posted\", \"Job URL\", \"Job Description\", \"Applications Count\", \"Industry\", \"Experience Level\", \"Search Keyword\"])\n",
    "    \n",
    "    seen_jobs = set()  # To avoid duplicate jobs\n",
    "    \n",
    "    for keyword in search_keywords:\n",
    "        print(f\"Searching for: {keyword}\")\n",
    "        params = {\"keywords\": keyword, \"location\": \"United Kingdom\", \"resultsToTake\": 100}\n",
    "        results_skipped = 0\n",
    "        \n",
    "        while True:\n",
    "            params[\"resultsToSkip\"] = results_skipped\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                job_data = response.json().get(\"results\", [])\n",
    "                if not job_data:\n",
    "                    break\n",
    "                \n",
    "                for job in job_data:\n",
    "                    job_url = job.get(\"jobUrl\", \"N/A\")\n",
    "                    if job_url in seen_jobs:\n",
    "                        continue  # Skip duplicates\n",
    "                    seen_jobs.add(job_url)\n",
    "                    \n",
    "                    writer.writerow([\n",
    "                        job.get(\"jobTitle\", \"N/A\"),\n",
    "                        job.get(\"employerName\", \"N/A\"),\n",
    "                        job.get(\"locationName\", \"N/A\"),\n",
    "                        job.get(\"minimumSalary\", \"N/A\"),\n",
    "                        job.get(\"maximumSalary\", \"N/A\"),\n",
    "                        job.get(\"contractType\", \"N/A\"),\n",
    "                        job.get(\"jobType\", \"N/A\"),\n",
    "                        job.get(\"date\", \"N/A\"),\n",
    "                        job_url,\n",
    "                        job.get(\"jobDescription\", \"N/A\").replace(\"\\n\", \" \").replace(\",\", \" \"),\n",
    "                        job.get(\"applications\", \"N/A\"),\n",
    "                        job.get(\"industry\", \"N/A\"),\n",
    "                        job.get(\"experienceRequired\", \"N/A\"),\n",
    "                        keyword\n",
    "                    ])\n",
    "                \n",
    "                results_skipped += len(job_data)\n",
    "                time.sleep(2)  # Avoid hitting API rate limits\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "print(f\"Job search completed. Data saved to {csv_path}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 2: Extract Full Job Descriptions with Selenium\n",
    "# ---------------------------------------------\n",
    "options = webdriver.SafariOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "driver = webdriver.Safari(options=options)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "results = []\n",
    "\n",
    "for job_url in df['Job URL'].tolist():\n",
    "    print(f\"Accessing job: {job_url}\")\n",
    "    \n",
    "    try:\n",
    "        driver.get(job_url)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'div.job-details-container_jobDetailsContainer__V1Mtj'))\n",
    "            )\n",
    "        except:\n",
    "            print(f\"Job details container not found for {job_url}\")\n",
    "            continue\n",
    "        \n",
    "        job_description = \"Description not found\"\n",
    "        try:\n",
    "            job_description_element = driver.find_element(By.CSS_SELECTOR, 'div.job-details_jobDescription__1dErB')\n",
    "            job_description = job_description_element.text\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if job_description == \"Description not found\":\n",
    "            try:\n",
    "                job_description_element = driver.find_element(By.CSS_SELECTOR, 'div.description span[itemprop=\"description\"]')\n",
    "                job_description = job_description_element.text\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        results.append([job_url, job_description])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing job: {job_url}\\n{e}\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df_descriptions = pd.DataFrame(results, columns=[\"Job URL\", \"Full Job Description\"])\n",
    "df_final = df.merge(df_descriptions, on=\"Job URL\", how=\"left\")\n",
    "df_final.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Full job descriptions extracted and updated in {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
